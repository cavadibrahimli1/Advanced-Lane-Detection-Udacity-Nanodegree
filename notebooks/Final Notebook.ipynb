{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Composition\n",
    "In this notebook I shall compose all the methods that I worked on so far and develop the final solution. A LOT of tinkering and moving around will be done, and some new features might be added, but I'll likely skip long sections for intermediate steps and directly include it in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T22:31:15.628607Z",
     "start_time": "2018-09-12T22:31:15.621587Z"
    },
    "tags": [
     "#path"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for root folder of the project...\n",
      "Root folder found. Now working in directory 'D:\\Linas\\projects\\CarND-Advanced-Lane-Lines'\n"
     ]
    }
   ],
   "source": [
    "# Set the right working folder to root folder of the project\n",
    "import os\n",
    "\n",
    "print(\"Looking for root folder of the project...\")\n",
    "for folder_depth in range(100): \n",
    "    if os.path.exists(\".git\"):\n",
    "        root_folder = os.getcwd()\n",
    "        print(\"Root folder found. Now working in directory '%s'\" % os.getcwd())\n",
    "        break\n",
    "    else:\n",
    "        print(\"Going up from '%s'\" % os.getcwd())\n",
    "        os.chdir(\"..\")\n",
    "else:\n",
    "    raise Exception(\"Root folder of the project not found. Terminating.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T23:05:33.735012Z",
     "start_time": "2018-09-12T23:05:33.723968Z"
    },
    "tags": [
     "#init",
     "=>path"
    ]
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import clips_array\n",
    "from moviepy.editor import ipython_display\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "class Plotter:\n",
    "    def __init__(self, columns, figsize=(20, 40)):\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        self.columns = columns\n",
    "        self.images = []\n",
    "        self.extra_plots = []\n",
    "        \n",
    "    def add_img(self, img, title):\n",
    "        assert len(img.shape) == 2 or img.shape[2] == 3\n",
    "        \n",
    "        cmap = None\n",
    "        if len(img.shape) == 2:\n",
    "            cmap = \"gray\"\n",
    "\n",
    "        self.images.append((img, title, cmap))\n",
    "        self.extra_plots.append([])\n",
    "        \n",
    "    def add_extra_to_last_img(self, xs, ys, plot_type):\n",
    "        assert plot_type in [\"line\"]\n",
    "        self.extra_plots[-1].append((xs, ys, plot_type))\n",
    "            \n",
    "    def plot(self):\n",
    "        j = 1  # Current column\n",
    "        i = 0\n",
    "        rows = ceil(len(self.images) // self.columns)\n",
    "        for img_index, (img, title, cmap) in enumerate(self.images):\n",
    "            # Draw iamge\n",
    "            ax = plt.subplot((rows / self.columns + 1) * self.columns, self.columns, i * self.columns + j)\n",
    "            ax.set_title(title)\n",
    "            \n",
    "            # Draw Extras\n",
    "            for xs, ys, plot_type in self.extra_plots[img_index]:\n",
    "                if plot_type == \"line\":\n",
    "                    plt.plot(xs, ys, color='yellow')\n",
    "            \n",
    "            # Show\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "            \n",
    "            if j % self.columns == 0:\n",
    "                j = 0\n",
    "                i += 1\n",
    "            j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T23:05:33.742005Z",
     "start_time": "2018-09-12T23:05:33.736993Z"
    },
    "tags": [
     "#constants"
    ]
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "YM_PER_PX = 30 / 720\n",
    "XM_PER_PX = 3.7 / 850  # empirically found that horizontal distance between lines is 850 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T23:05:33.784145Z",
     "start_time": "2018-09-12T23:05:33.745013Z"
    },
    "tags": [
     "#prev-work",
     "=>path",
     "=>init",
     "=>constants"
    ]
   },
   "outputs": [],
   "source": [
    "def apply_precomputed_undistortion(img, mtx_filename, dist_filename):\n",
    "    mtx = np.load(mtx_filename)\n",
    "    dist = np.load(dist_filename)\n",
    "    undist_img = cv2.undistort(img, mtx, dist)\n",
    "    return undist_img\n",
    "\n",
    "\n",
    "def threshold_image(img):\n",
    "    # Saturation-based thresholding\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    s_thresh_value = 150\n",
    "    s_thresh = np.zeros_like(s_channel)\n",
    "    s_thresh[s_channel > s_thresh_value] = 1\n",
    "    \n",
    "    # Edge Detection\n",
    "    red = img[:, :, 0]\n",
    "    sobel_kernel = 25\n",
    "    assert sobel_kernel >= 3 and sobel_kernel % 2 == 1\n",
    "    sobel_x = cv2.Sobel(red, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(red, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    sobel_x = np.absolute(sobel_x)\n",
    "    sobel_y = np.absolute(sobel_y)\n",
    "\n",
    "    # Magnitude\n",
    "    magnitude = (sobel_x**2 + sobel_y**2)**.5\n",
    "    mag_norm = np.uint8(255 * magnitude / np.max(magnitude))\n",
    "    mag_thresh_value = 30\n",
    "    mag_thresh = np.zeros_like(mag_norm, dtype=np.uint8)\n",
    "    mag_thresh[mag_norm > mag_thresh_value] = 1\n",
    "    \n",
    "    # Direction\n",
    "    atan = np.arctan2(sobel_y, sobel_x)\n",
    "    atan_thresh_min = 0.8\n",
    "    atan_thresh_max = 1.2\n",
    "    dir_thresh = np.zeros_like(atan, dtype=np.uint8)\n",
    "    dir_thresh[(atan > atan_thresh_min) & (atan <= atan_thresh_max)] = 1\n",
    "    \n",
    "    # Combinations\n",
    "    mag_and_dir = cv2.bitwise_and(mag_thresh, dir_thresh)    \n",
    "    grad_or_color = cv2.bitwise_or(mag_and_dir, s_thresh)\n",
    "    \n",
    "    return grad_or_color\n",
    "\n",
    "\n",
    "def warp_perspective(img, x_offset=200, y_offset=100, new_image_shape=(1000, 1000), flags=cv2.INTER_LINEAR):    \n",
    "    # Detect Lines\n",
    "    # Luckily, the camera resolution is 1280 x 720 in all iamges / videos we're given. This means I can hardode the values.\n",
    "    top_left  = [578,  463]\n",
    "    top_right = [706,  463]\n",
    "    bot_right = [1043, 677]\n",
    "    bot_left  = [267,  677]\n",
    "    src_corners = np.float32([top_left, top_right, bot_right, bot_left])\n",
    "    \n",
    "    line_img = np.zeros(new_image_shape, dtype=np.uint8)\n",
    "    \n",
    "    new_top_left  = [x_offset, y_offset]\n",
    "    new_top_right = [line_img.shape[1] - x_offset, y_offset]\n",
    "    new_bot_right = [line_img.shape[1] - x_offset, line_img.shape[0] - y_offset]\n",
    "    new_bot_left  = [x_offset, line_img.shape[0] - y_offset]\n",
    "    dst_corners = np.float32([new_top_left, new_top_right, new_bot_right, new_bot_left])\n",
    "    \n",
    "    transform_matrix = cv2.getPerspectiveTransform(src_corners, dst_corners)\n",
    "    inv_transform_matrix = cv2.getPerspectiveTransform(dst_corners, src_corners)\n",
    "    warped = cv2.warpPerspective(img, transform_matrix, line_img.shape[::-1], flags=flags)\n",
    "\n",
    "    return warped, transform_matrix, inv_transform_matrix\n",
    "\n",
    "\n",
    "def retrieve_polylines(warped, draw_windows=True):    \n",
    "    \"\"\"\n",
    "    Takes in the warped thresholds to find polylines on the road\n",
    "    \"\"\"\n",
    "    \n",
    "    # find histogram of half-height\n",
    "    warped_y_midpoint = warped.shape[0] // 2\n",
    "    histogram = np.sum(warped[warped_y_midpoint:, :], axis=0)\n",
    "    out_img = np.dstack((warped, warped, warped))\n",
    "    \n",
    "    # find base points on both sides - max values\n",
    "    hist_x_midpoint = np.int(histogram.shape[0] // 2)\n",
    "    left_x_base = np.argmax(histogram[:hist_x_midpoint])\n",
    "    right_x_base = np.argmax(histogram[hist_x_midpoint:]) + hist_x_midpoint\n",
    "\n",
    "    # Hyperparameters\n",
    "    win_min_pix = 50  # minimum number of pixels found to recenter window\n",
    "    win_num = 9  # the number of sliding windows\n",
    "    win_half_width = 200 // 2\n",
    "    win_height = np.int(warped.shape[0] // win_num)\n",
    "    \n",
    "    # Nonzero pixel indices\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    \n",
    "    # Init current midpoint variables and index lists\n",
    "    left_x_current = left_x_base\n",
    "    right_x_current = right_x_base\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    for win_index in range(win_num):\n",
    "        # Iterate over windows from the bottom, setting boundaries\n",
    "        win_y_low = warped.shape[0] - (win_index + 1) * win_height\n",
    "        win_y_high = warped.shape[0] - win_index * win_height\n",
    "        win_x_left_low   = left_x_current - win_half_width\n",
    "        win_x_left_high  = left_x_current  + win_half_width\n",
    "        win_x_right_low  = right_x_current - win_half_width\n",
    "        win_x_right_high = right_x_current + win_half_width\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if draw_windows:\n",
    "            cv2.rectangle(out_img, (win_x_left_low,  win_y_low), (win_x_left_high,  win_y_high), color=(0, 255, 0), thickness=3)\n",
    "            cv2.rectangle(out_img, (win_x_right_low, win_y_low), (win_x_right_high, win_y_high), color=(0, 255, 0), thickness=3)\n",
    "        \n",
    "        # Conjoin binary index arrays, retrieve y coords of nonzero pixels in each window\n",
    "        good_left_inds = (\n",
    "            (nonzero_x >= win_x_left_low) &\n",
    "            (nonzero_x < win_x_left_high) &\n",
    "            (nonzero_y >= win_y_low) &\n",
    "            (nonzero_y < win_y_high)\n",
    "        ).nonzero()[0]\n",
    "        good_right_inds = (\n",
    "            (nonzero_x >= win_x_right_low) &\n",
    "            (nonzero_x < win_x_right_high) &\n",
    "            (nonzero_y >= win_y_low) &\n",
    "            (nonzero_y < win_y_high)\n",
    "        ).nonzero()[0]\n",
    "        \n",
    "        # Append whole array to a global list\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If enough pixels, shift mean x coordinate of the \n",
    "        if len(good_left_inds) > win_min_pix:\n",
    "            nonzero_x_in_win = nonzero_x[good_left_inds]\n",
    "            left_x_current = np.int(np.mean(nonzero_x_in_win))\n",
    "        if len(good_right_inds) > win_min_pix:\n",
    "            nonzero_x_in_win = nonzero_x[good_right_inds]\n",
    "            right_x_current = np.int(np.mean(nonzero_x_in_win))\n",
    "\n",
    "    # Flatten global list to get all y indices of line pixels for each side\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError as e:\n",
    "        raise e\n",
    "\n",
    "    # Get all (i,j) indices of nonzero pixels within windows, for each side \n",
    "    left_x = nonzero_x[left_lane_inds]\n",
    "    left_y = nonzero_y[left_lane_inds] \n",
    "    right_x = nonzero_x[right_lane_inds]\n",
    "    right_y = nonzero_y[right_lane_inds]\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[left_y, left_x] = [255, 0, 0]\n",
    "    out_img[right_y, right_x] = [0, 0, 255]\n",
    "    \n",
    "    # Polyfit using all the points\n",
    "    left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    right_fit = np.polyfit(right_y, right_x, 2)\n",
    "    \n",
    "    # Get real-scaled polylines for curvature calculation\n",
    "    scaled_left_fit = np.polyfit(left_y * YM_PER_PX, left_x * XM_PER_PX, 2)\n",
    "    scaled_right_fit = np.polyfit(right_y * YM_PER_PX, right_x * XM_PER_PX, 2)\n",
    "\n",
    "    return out_img, left_fit, right_fit, (scaled_left_fit, scaled_right_fit)\n",
    "\n",
    "\n",
    "def generate_polyline_plots(warped_shape, left_fit, right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    plot_y = np.linspace(0, warped_shape[0] - 1, warped_shape[0])\n",
    "\n",
    "    left_fit_x = left_fit[0] * plot_y**2 + left_fit[1] * plot_y + left_fit[2]\n",
    "    right_fit_x = right_fit[0] * plot_y**2 + right_fit[1] * plot_y + right_fit[2]\n",
    "\n",
    "    # # Now call:\n",
    "    # plotter.add_img(out_img, \"warped image\")\n",
    "    # plotter.add_extra_to_last_img(left_fit_x,  plot_y, \"line\")\n",
    "    # plotter.add_extra_to_last_img(right_fit_x, plot_y, \"line\")\n",
    "    \n",
    "    return left_fit_x, right_fit_x, plot_y\n",
    "    \n",
    "def fit_polynomial(x, coefficients):\n",
    "    res = 0\n",
    "    for power, coeff in enumerate(coefficients[::-1]):\n",
    "        res += coeff * x**power\n",
    "    return res\n",
    "\n",
    "def get_lane_area(warped_line_img, inv_transformation_matrix, original_img_shape, left_fit, right_fit):\n",
    "    # Area between two polylines\n",
    "    all_pts = np.zeros(warped_line_img.shape[:2], dtype=np.uint8)\n",
    "    for y in range(warped_line_img.shape[0]):\n",
    "        poly_left = int(fit_polynomial(y, left_fit))\n",
    "        poly_right = int(fit_polynomial(y, right_fit))\n",
    "        all_pts[y, poly_left:poly_right] = 1\n",
    "    \n",
    "    polyfilled = warped_line_img.copy()\n",
    "    polyfilled[all_pts == 1] = np.array([0, 255, 0])\n",
    "    \n",
    "    # Dewarp\n",
    "    dewarped = cv2.warpPerspective(polyfilled, inv_transformation_matrix, original_img_shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return dewarped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T23:05:33.801168Z",
     "start_time": "2018-09-12T23:05:33.787127Z"
    },
    "tags": [
     "#heuristics",
     "=>path",
     "=>init",
     "=>prev-work",
     "=>constants"
    ]
   },
   "outputs": [],
   "source": [
    "def threshold_yellow_lines(hls_img):\n",
    "    \"\"\"\n",
    "    This function attempts to detect only the yellow lines.\n",
    "    \n",
    "    Why try to make a general function for detecting all lane lines, when we can easily distinguish two types - yellow and white?\n",
    "    (actually, there's a third type, when road side is used as a line, with no explicit line marking)\n",
    "    \n",
    "    I have consulted https://driversed.com/driving-information/signs-signals-and-markings/markings-colors-patterns-meaning.aspx,\n",
    "    verifying that only two color types exist.\n",
    "    \"\"\"\n",
    "    # Convert to hls\n",
    "    h_channel = hls_img[:, :, 0]\n",
    "    l_channel = hls_img[:, :, 1]\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    thresh = np.zeros_like(h_channel)\n",
    "    thresh[\n",
    "        (h_channel >= 11) & (h_channel <= 30) &\n",
    "        (s_channel >= 50) &\n",
    "        (l_channel >= 150)\n",
    "    ] = 255\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "def threshold_strong_sat_light(hls_img):\n",
    "    h_channel = hls_img[:, :, 0]\n",
    "    l_channel = hls_img[:, :, 1]\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    thresh = np.zeros_like(h_channel)\n",
    "    thresh[\n",
    "        (s_channel >= 150) &\n",
    "        (l_channel >= 128)\n",
    "    ] = 255\n",
    "\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def apply_sobel(channel, kernel_size):\n",
    "    assert kernel_size >= 3 and kernel_size % 2 == 1\n",
    "    sobel_x = cv2.Sobel(channel, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobel_y = cv2.Sobel(channel, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    \n",
    "    sobel_x = np.absolute(sobel_x)\n",
    "    sobel_y = np.absolute(sobel_y)\n",
    "    \n",
    "    return sobel_x, sobel_y\n",
    "\n",
    "\n",
    "def threshold_magnitude(sobel_x, sobel_y):\n",
    "    magnitude = (sobel_x**2 + sobel_y**2)**.5\n",
    "    mag_norm = np.uint8(255 * magnitude / np.max(magnitude))\n",
    "    mag_thresh_value = 30\n",
    "    mag_thresh = np.zeros_like(mag_norm, dtype=np.uint8)\n",
    "    mag_thresh[mag_norm > mag_thresh_value] = 255\n",
    "    \n",
    "    return mag_thresh\n",
    "\n",
    "\n",
    "def threshold_direction(sobel_x, sobel_y):\n",
    "    atan = np.arctan2(sobel_y, sobel_x)  # returns results in range [0.0, 1.57079632679]\n",
    "    atan_thresh_max = 1.2\n",
    "    dir_thresh = np.zeros_like(atan, dtype=np.uint8)\n",
    "    dir_thresh[(atan <= atan_thresh_max)] = 255\n",
    "    \n",
    "    return dir_thresh\n",
    "\n",
    "\n",
    "def morph_close(thresh, kernel_size):\n",
    "    assert kernel_size >= 3 and kernel_size % 2 == 1\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return closed\n",
    "    \n",
    "    \n",
    "def get_distorted_hood_mask():\n",
    "    \"\"\"\n",
    "    Returns the original image mask with the hood area masked\n",
    "    \"\"\"\n",
    "    mask_filename = os.path.join(root_folder, \"masks\", \"distorted_hood_mask.png\")\n",
    "#     mask_rgb = mpimg.imread(mask_filename)\n",
    "    mask_bgr = cv2.imread(mask_filename)\n",
    "    \n",
    "    \n",
    "    mask = np.zeros(mask_bgr.shape[:2], dtype=np.uint8)\n",
    "    mask[\n",
    "        (mask_bgr[:, :, 0] == 255) & \n",
    "        (mask_bgr[:, :, 1] == 255) & \n",
    "        (mask_bgr[:, :, 2] == 0)\n",
    "    ] = 255\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "                    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def update_history(datapoint, history_list, history_length):\n",
    "    \"\"\"\n",
    "    In place, update a history list of arbitrary data with a new datapoint\n",
    "    \"\"\"\n",
    "    history_list.append(datapoint)\n",
    "    if len(history_list) > history_length:\n",
    "        del history_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T21:52:01.766749Z",
     "start_time": "2018-09-11T21:52:01.756222Z"
    },
    "tags": [
     "#curvature",
     "=>path",
     "=>init",
     "=>constants"
    ]
   },
   "outputs": [],
   "source": [
    "def update_scaled_history(scaled_lines, scaled_left_lines, scaled_right_lines, line_history_length):\n",
    "    scaled_left_fit, scaled_right_fit = scaled_lines\n",
    "\n",
    "    # Average the scaled lines for curvature calculation\n",
    "    update_history(scaled_left_fit, scaled_left_lines, line_history_length)\n",
    "    scaled_avg_left_fit = np.mean(scaled_left_lines, axis=0)\n",
    "\n",
    "    update_history(scaled_right_fit, scaled_right_lines, line_history_length)\n",
    "    scaled_avg_right_fit = np.mean(scaled_right_lines, axis=0)\n",
    "\n",
    "    # For car offset calculation, find an x coordinate given a fixed y\n",
    "    y_point = 400 / 720 * YM_PER_PX  # particular y_pixel / image height\n",
    "\n",
    "    scaled_left_fit_x = scaled_avg_left_fit[0] * y_point**2 + scaled_avg_left_fit[1] * y_point + scaled_avg_left_fit[2]\n",
    "    update_history(scaled_left_fit_x, left_line_centerpoints, line_history_length)\n",
    "\n",
    "    scaled_right_fit_x = scaled_avg_right_fit[0] * y_point**2 + scaled_avg_right_fit[1] * y_point + scaled_avg_right_fit[2]\n",
    "    update_history(scaled_right_fit_x, right_line_centerpoints, line_history_length)\n",
    "     \n",
    "        \n",
    "def pick_best_line(left_centerpoint_history, right_centerpoint_history, history_length):\n",
    "    \n",
    "    pick_left = False\n",
    "    if np.var(left_centerpoint_history) < np.var(right_centerpoint_history):\n",
    "        pick_left = True\n",
    "        \n",
    "    return pick_left\n",
    "\n",
    "        \n",
    "def find_car_offset(total_width, left_fit, right_fit, pick_left, gap_between_lanes=3.7):\n",
    "    if pick_left:\n",
    "        right_fit = left_fit + gap_between_lanes\n",
    "    else:\n",
    "        left_fit = right_fit - gap_between_lanes\n",
    "\n",
    "    mid = (left_fit + right_fit) / 2\n",
    "    car_offset = (total_width - mid)\n",
    "    \n",
    "    return car_offset\n",
    "\n",
    "\n",
    "def find_curvature_radius(y_point, left_fit, right_fit, pick_left):\n",
    "    if pick_left:\n",
    "        curverad  = ((1 + (2 * left_fit[0] * y_point  + left_fit[1]) ** 2) ** 1.5)  / np.absolute(2 * left_fit[0])\n",
    "    else:\n",
    "        curverad = ((1 + (2 * right_fit[0] * y_point + right_fit[1]) ** 2) ** 1.5) / np.absolute(2 * right_fit[0])\n",
    "\n",
    "    return curverad\n",
    "\n",
    "\n",
    "def draw_text(image, text, location):\n",
    "    \"\"\"\n",
    "    In place, draw text onto an image\n",
    "    \"\"\"\n",
    "    cv2.putText(\n",
    "        img=image,\n",
    "        text=text,\n",
    "        org=location,\n",
    "        fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "        fontScale=2,\n",
    "        color=(255,255,255),\n",
    "        thickness=2,\n",
    "        lineType=cv2.FILLED\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T21:52:01.785298Z",
     "start_time": "2018-09-11T21:52:01.769757Z"
    },
    "tags": [
     "#process",
     "=>prev-work",
     "=>heuristics",
     "=>curvature"
    ]
   },
   "outputs": [],
   "source": [
    "def make_color(func):\n",
    "    \"\"\"\n",
    "    Converts the result to a color image if a grayscale is provided\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        img = func(*args, **kwargs)\n",
    "        if len(np.shape(img)) == 2:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "@make_color\n",
    "def process_img(rgb_img,\n",
    "                left_lines, right_lines, line_history_length,\n",
    "                scaled_left_lines, scaled_right_lines,\n",
    "                left_line_centerpoints, right_line_centerpoints):\n",
    "    # Get hood mask to ignore hood area\n",
    "    dist_hood_mask = get_distorted_hood_mask()\n",
    "        \n",
    "    # Undistort Image\n",
    "    mtx_filename  = os.path.join(root_folder, \"params\", \"camera_matrix.npy\")\n",
    "    dist_filename = os.path.join(root_folder, \"params\", \"dist_coeffs.npy\")\n",
    "    undistorted = apply_precomputed_undistortion(rgb_img, mtx_filename, dist_filename)\n",
    "    hood_mask = apply_precomputed_undistortion(dist_hood_mask, mtx_filename, dist_filename)    \n",
    "    hood_mask[hood_mask < 100] = 0     # Undo the effects of linear interpollation\n",
    "    hood_mask[hood_mask >= 100] = 255\n",
    "\n",
    "    # RGB -> HLS\n",
    "    hls_img = cv2.cvtColor(undistorted, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls_img[:, :, 0]\n",
    "    l_channel = hls_img[:, :, 1]\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    # Find x and y edges\n",
    "    l_sobel_x, l_sobel_y = apply_sobel(l_channel, 25)\n",
    "    s_sobel_x, s_sobel_y = apply_sobel(s_channel, 25)\n",
    "\n",
    "    # Threshold by edge magnitude\n",
    "    l_thresh_mag = threshold_magnitude(l_sobel_x, l_sobel_y)\n",
    "    s_thresh_mag = threshold_magnitude(s_sobel_x, s_sobel_y)\n",
    "    thresh_mag = cv2.bitwise_or(l_thresh_mag, s_thresh_mag)\n",
    "    \n",
    "    # Threshold by edge direction\n",
    "    l_thresh_dir = threshold_direction(l_sobel_x, l_sobel_y)  # I results are slightly better with just lightness-based threshold than both.\n",
    "    \n",
    "    # Combine edge magnitude and direction\n",
    "    thresh_edges = cv2.bitwise_and(thresh_mag, l_thresh_dir)\n",
    "\n",
    "    # Fill in gaps between edges\n",
    "    closed_edges = morph_close(thresh_edges, 5)\n",
    "    \n",
    "    # Apply hood mask\n",
    "    closed_edges = cv2.bitwise_and(closed_edges, hood_mask)\n",
    "    \n",
    "    warped, transformation_matrix, inv_transformation_matrix = warp_perspective(\n",
    "        closed_edges, x_offset=200, y_offset=100, new_image_shape=closed_edges.shape[:2]\n",
    "    )\n",
    "    \n",
    "    # Fit a polyline\n",
    "    warped_line_img, left_fit, right_fit, scaled_lines = retrieve_polylines(warped, draw_windows=False)\n",
    "\n",
    "    # Average the lines\n",
    "    update_history(left_fit, left_lines, line_history_length)\n",
    "    avg_left_fit = np.mean(left_lines, axis=0)\n",
    "    \n",
    "    update_history(right_fit, right_lines, line_history_length)\n",
    "    avg_right_fit = np.mean(right_lines, axis=0)\n",
    "    \n",
    "    # Draw the area\n",
    "    dewarped = get_lane_area(warped_line_img, inv_transformation_matrix, rgb_img.shape, avg_left_fit, avg_right_fit)\n",
    "    \n",
    "    # Overlay\n",
    "    alpha = 0.2\n",
    "    combined_img = np.zeros_like(undistorted)\n",
    "    cv2.addWeighted(dewarped, alpha, undistorted, 1 - alpha, 0, combined_img)\n",
    "    \n",
    "    # Scale lines for curvature detection \n",
    "    if scaled_lines is not None:\n",
    "        update_scaled_history(scaled_lines, scaled_left_lines, scaled_right_lines, line_history_length)\n",
    "        scaled_left_fit, scaled_right_fit = scaled_lines\n",
    "    \n",
    "        # Select line where x coordinate variance is the least, given fixed y\n",
    "        pick_left = pick_best_line(left_line_centerpoints, right_line_centerpoints, line_history_length)\n",
    "        \n",
    "        # Find and draw car offset\n",
    "        car_offset = find_car_offset(np.shape(combined_img)[1] / 2 * XM_PER_PX,\n",
    "            left_line_centerpoints[-1], right_line_centerpoints[-1], pick_left\n",
    "        )\n",
    "        car_offset_text = \"Vehicle is {car_offset: .2f}m {direction_word} of center\"\n",
    "        car_offset_text = car_offset_text.format(\n",
    "            car_offset=np.absolute(car_offset), direction_word=\"left\" if car_offset < 0 else \"right\"\n",
    "        )    \n",
    "        draw_text(combined_img, car_offset_text, (50, 100))\n",
    "        \n",
    "        ### Find and draw lane curvature\n",
    "        y_point = 400 / 720 * YM_PER_PX  # particular y_pixel / image height\n",
    "        curvature = find_curvature_radius(\n",
    "            y_point, np.mean(scaled_left_lines, axis=0), np.mean(scaled_right_lines, axis=0), pick_left\n",
    "        )\n",
    "        curvature_text = \"Radius of Curvature = {curvature: d}(m)\".format(curvature=int(curvature))\n",
    "        draw_text(combined_img, curvature_text, (50, 50))\n",
    "    \n",
    "    return combined_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T22:00:57.628577Z",
     "start_time": "2018-09-11T21:52:01.788808Z"
    },
    "tags": [
     "#run-on-videos",
     "=>prev-work",
     "=>process",
     "=>path"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video D:\\Linas\\projects\\CarND-Advanced-Lane-Lines\\results\\project_video.mp4\n",
      "[MoviePy] Writing video D:\\Linas\\projects\\CarND-Advanced-Lane-Lines\\results\\project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [08:54<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: D:\\Linas\\projects\\CarND-Advanced-Lane-Lines\\results\\project_video.mp4 \n",
      "\n",
      "Wall time: 8min 55s\n"
     ]
    }
   ],
   "source": [
    "video_in_folder  = os.path.join(root_folder, \"data\")\n",
    "video_out_folder = os.path.join(root_folder, \"results\")\n",
    "video_in_pattern = os.path.join(video_in_folder, \"*.mp4\")\n",
    "video_in_fnames  = glob.glob(video_in_pattern)\n",
    "video_out_fnames = [os.path.join(video_out_folder, os.path.basename(fname)) for fname in video_in_fnames]\n",
    "\n",
    "only_use_videos = [2]  # Only use videos with indices specified here\n",
    "use_subclip = False  # For testing\n",
    "\n",
    "for i in range(len(video_in_fnames)):\n",
    "    if only_use_videos and i not in only_use_videos:\n",
    "        continue\n",
    "    video_in_fname  = video_in_fnames[i]\n",
    "    video_out_fname = video_out_fnames[i]\n",
    "    \n",
    "    clip = VideoFileClip(video_in_fname)\n",
    "    if use_subclip:\n",
    "        clip = clip.subclip(0, 3)\n",
    "        \n",
    "    LINE_HISTORY_LENGTH = 7\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    scaled_left_lines = []\n",
    "    scaled_right_lines = []\n",
    "    \n",
    "    # used for selecting the more stable line for curvature estimation\n",
    "    left_line_centerpoints = []\n",
    "    right_line_centerpoints = []\n",
    "    \n",
    "    processed_clip = clip.fl_image(\n",
    "        lambda x: process_img(\n",
    "            x,\n",
    "            left_lines, right_lines, LINE_HISTORY_LENGTH,\n",
    "            scaled_left_lines, scaled_right_lines,\n",
    "            left_line_centerpoints, right_line_centerpoints\n",
    "        )\n",
    "    )\n",
    "\n",
    "    %time processed_clip.write_videofile(video_out_fname, audio=False)\n",
    "    \n",
    "    clip.close()\n",
    "    processed_clip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T19:54:19.926053Z",
     "start_time": "2018-08-29T19:54:09.391567Z"
    },
    "tags": [
     "=>path",
     "=>init",
     "#combination"
    ]
   },
   "outputs": [],
   "source": [
    "# Display the videos\n",
    "video_in_folder  = os.path.join(root_folder, \"data\")\n",
    "video_out_folder = os.path.join(root_folder, \"results\")\n",
    "video_in_pattern = os.path.join(video_in_folder, \"*.mp4\")\n",
    "video_in_fnames  = glob.glob(video_in_pattern)\n",
    "video_out_fnames = [os.path.join(video_out_folder, os.path.basename(fname)) for fname in video_in_fnames]\n",
    "\n",
    "video_index = 0\n",
    "use_subclip = False\n",
    "\n",
    "composed_out_folder = os.path.join(root_folder, \"results\", \"intermediate\")\n",
    "composed_out_fname = os.path.join(composed_out_folder, \"yellow_detection_\" + os.path.basename(video_out_fnames[video_index]))\n",
    "\n",
    "original_clip = VideoFileClip(video_in_fnames[video_index]).resize(0.5)\n",
    "modified_clip = VideoFileClip(video_out_fnames[video_index]).resize(0.5)\n",
    "if use_subclip:\n",
    "    original_clip = original_clip.subclip(0, 10)\n",
    "    modified_clip = modified_clip.subclip(0, 10)\n",
    "composed_clip = clips_array([[original_clip, modified_clip]])\n",
    "\n",
    "composed_clip.write_videofile(composed_out_fname, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T09:44:53.591586Z",
     "start_time": "2018-08-19T09:44:53.575631Z"
    }
   },
   "outputs": [],
   "source": [
    "original_clip.close()\n",
    "modified_clip.close()\n",
    "composed_clip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Tools\n",
    "This should probably be split into a separate notebook, but I need some small tools to tinker with. E.g. I need to save one frame of an image to analyze the hue and lightness value of yellow line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T23:05:37.177730Z",
     "start_time": "2018-09-12T23:05:33.803169Z"
    },
    "tags": [
     "#aux-tools",
     "=>prev-work",
     "=>heuristics",
     "=>path"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Frames produced: 47\n"
     ]
    }
   ],
   "source": [
    "video_in_name  = os.path.join(root_folder, \"results\", \"intermediate\", \"best edge threshold sob25_m30-_L_d-09 closed harder_challenge_video.mp4\")\n",
    "out_folder = os.path.join(root_folder, \"results\", \"intermediate\")\n",
    "\n",
    "clip = VideoFileClip(video_in_name)\n",
    "\n",
    "for i in range(int(clip.duration)):\n",
    "    out_filename = os.path.join(out_folder, \"frame_%d.png\" % i)\n",
    "    clip.save_frame(out_filename, t=i)\n",
    "    break\n",
    "    \n",
    "print(\"Done! Frames produced: %d\" % clip.duration)\n",
    "clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T22:33:19.583438Z",
     "start_time": "2018-09-12T22:33:19.097146Z"
    }
   },
   "outputs": [],
   "source": [
    "img_in_path  = os.path.join(root_folder, \"results\", \"intermediate\", \"distorted and undistorted\", \"frame 0.png\")\n",
    "img_out_path = os.path.join(root_folder, \"results\", \"intermediate\", \"distorted and undistorted\", \"frame 0 - undistorted.png\")\n",
    "img = mpimg.imread(img_in_path)\n",
    "\n",
    "mtx_filename  = os.path.join(root_folder, \"params\", \"camera_matrix.npy\")\n",
    "dist_filename = os.path.join(root_folder, \"params\", \"dist_coeffs.npy\")\n",
    "\n",
    "undist_img = apply_precomputed_undistortion(img, mtx_filename, dist_filename)\n",
    "\n",
    "plt.imsave(img_out_path, undist_img)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
